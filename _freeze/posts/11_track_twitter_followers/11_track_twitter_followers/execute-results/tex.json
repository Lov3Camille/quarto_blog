{
  "hash": "74b9de1b2bdef2387467ec460e063bf0",
  "result": {
    "markdown": "---\ntitle: \"Use {lubridate} and {rtweet} to analyze your Twitter timeline\"\ndate: '2022-05-06'\ncategories: [\"Visualization\", \"API\"]\ndescription: \"We take a quick look at the rtweet and lubridate package. These help you to analyse your Twitter timeline. And they helped me to visualize my follower count as I reached 1000 followers this week.\"\nexecute: \n  message: false\n  warning: false\n  collapse: false\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n:::\n\n\n\nThis week, I am oddly proud to announce that I have reached 1000 followers on [Twitter](https://twitter.com/rappa753).\nCheck out the visualization that I have created for this joyous occasion.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](final_viz.png){width=11.69in}\n:::\n:::\n\n\n\nTo me, my rising follower count and the somewhat regular mails that I receive are a \nsign that people like to read my blog.\nAnd to thank you all for following my work, let me give you a quick intro to the\npackages `rtweet` and `lubridate`.\nThese were instrumental in creating the above visual.\n\n## Working with rtweet\n\nAt the end of February 2022, I wondered how my follower count evolves over time.\nUnfortunately, this is not something Twitter shows you by default.\nThe Analytics page only shows me the change within my last 28 days.\nTo overcome this drawback, I consulted the `rtweet` package which is a fabulous \npackage that lets you interact with Twitter's API through R.\n\nIn my case, I only do rudimentary work with it and track my followers over time.\nFor this to work, I have set up an R script that runs every \nhour to download a list of my followers.\nEach hour, the list's length tells me how many followers I have.\n\nIf you want to do the same, install the package first.\nMake sure to install the development version from GitHub, though.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremotes::install_github(\"rOpenSci/rtweet\")\n```\n:::\n\n\n\n\n### Basic functionalities\n\n`rtweet` comes with a lot of convenient function.\nMost of these start with `get_`.\nFor instance, there are\n\n* `get_followers()`: This is the function to get a list of an account's followers.\n* `get_timeline()`: This gives you the a user's timeline like tweets, replies and mentions.\n* `get_retweets()`: This gives you the most recent retweets of a given tweet.\n\nMy aforementioned R script just runs `get_followers()` and\ncomputes the number of rows of the resulting tibble.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rtweet)\ntib <- get_followers('rappa753')\ntib\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,220 x 2\n   from_id             to_id   \n   <chr>               <chr>   \n 1 976412463460691968  rappa753\n 2 1288036436713680897 rappa753\n 3 265753880           rappa753\n 4 93241327            rappa753\n 5 1243010518027100160 rappa753\n 6 1242489571109208070 rappa753\n 7 308069851           rappa753\n 8 369966562           rappa753\n 9 259654522           rappa753\n10 356697637           rappa753\n# ... with 2,210 more rows\n# i Use `print(n = ...)` to see more rows\n```\n:::\n\n```{.r .cell-code}\nnrow(tib)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2220\n```\n:::\n:::\n\n\n\n\n\nFor my above visualization, I used `get_timeline()` to extract my five most popular tweets.\nHere, I ranked the popularity by the count of likes resp. \"favorites\" as `rtweet` likes to call it.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntl <- get_timeline('rappa753', n = 1000)\ntl_slice <- tl %>% \n  slice_max(favorite_count, n = 5) %>% \n  select(created_at, full_text, favorite_count, retweet_count) \ntl_slice\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 4\n  created_at          full_text                                  favor~1 retwe~2\n  <dttm>              <chr>                                        <int>   <int>\n1 2022-06-18 15:46:22 \"Ever heard of logistic regression? Or Po~    1460     231\n2 2022-07-10 16:18:10 \"The #rstats ecosystem makes splitting a ~     661      96\n3 2022-03-05 21:56:33 \"The fun thing about getting better at #g~     507      82\n4 2022-07-09 13:21:04 \"Creating calendar plots with #rstats is ~     419      53\n5 2022-02-19 18:32:23 \"Ever wanted to use colors in #ggplot2 mo~     347      56\n# ... with abbreviated variable names 1: favorite_count, 2: retweet_count\n```\n:::\n:::\n\n\n\nNotice that I tweeted two of these before I started tracking my followers.\nConsequently, I ignored them for my visualization.\n\nUnfortunately, the `rtweet` package cannot do everything.\nFor example, the snapshot functionality `tweet_shot()` does not work anymore.\nI think that's because the Twitter API changed.\n\nThis bothered me during the [30 day chart challenge](https://twitter.com/30DayChartChall) in April because I wanted to automatically extract great visualizations from Twitter.\nBut as `tweet_shot()` was not working, I had to call Twitter's API manually without `rtweet`.\nIf you're curious about how that works, check out my [corresponding blog post](https://albert-rapp.de/posts/09_get_twitter_posts_into_your_notetaking_system/09_get_twitter_posts_into_your_notetaking_system.html).\nThere, I've also explained how to set up a script that gets executed, say, every \nhour automatically.\n\n### Setting up a Twitter app\n\nThis pretty much explains how `rtweet` works.\nIn general, it is really easy to use.\nAnd if you only want to use it only occasionally, there is not much more to it.\n\nHowever, if you want to use the package more often - as in calling the API every hour -\nthen you need to set up a Twitter app.\nYou can read up on how that works in the \"Preparations\" section of the [above blog post](https://albert-rapp.de/posts/09_get_twitter_posts_into_your_notetaking_system/09_get_twitter_posts_into_your_notetaking_system.html).\nOnce you've got that down, your `rtweet` calls can be authenticated through your\nTwitter app like so.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nauth <- rtweet::rtweet_app(\n  bearer_token = keyring::key_get('twitter-bearer-token', keyring = 'blogpost')\n)\nauth_as(auth)\n```\n:::\n\n\n\nHere, I have used the `keyring` package to hide the bearer token of my Twitter app.\nIf that doesn't mean anything to you, let me once again refer to the [above blog post](https://albert-rapp.de/posts/09_get_twitter_posts_into_your_notetaking_system/09_get_twitter_posts_into_your_notetaking_system.html).\nThe important thing is that after these lines ran your `rtweet` calls get funneled through your\nown Twitter app.\n\n## Working with lubridate\n\nAs you saw above, the timeline that we extracted and saved in `rtweet` contains\ntime data.\nHere it is once again.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntl_slice\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 4\n  created_at          full_text                                  favor~1 retwe~2\n  <dttm>              <chr>                                        <int>   <int>\n1 2022-06-18 15:46:22 \"Ever heard of logistic regression? Or Po~    1460     231\n2 2022-07-10 16:18:10 \"The #rstats ecosystem makes splitting a ~     661      96\n3 2022-03-05 21:56:33 \"The fun thing about getting better at #g~     507      82\n4 2022-07-09 13:21:04 \"Creating calendar plots with #rstats is ~     419      53\n5 2022-02-19 18:32:23 \"Ever wanted to use colors in #ggplot2 mo~     347      56\n# ... with abbreviated variable names 1: favorite_count, 2: retweet_count\n```\n:::\n:::\n\n\n\nSadly, working with times and dates is rarely pleasant.\nBut we can make our life a bit easier by using the `lubridate` package which was made for that.\nTo show you how it works, it is probably best to show you a couple of use cases.\n\nAll of these will be taken from what I had to deal with to create my celebratory\nvisualization.\nBut I simplified it to minimal examples for this blog post.\nMore use cases can be found in the [lubridate cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/lubridate.pdf) or the [tidyverse cookbook ressource](https://bookdown.org/Tazinho/Tidyverse-Cookbook/dates-and-times.html) by Malte Grosser.\n\n### Parse dates and times\n\n**EDIT July 13, 2022:** After moving my blog to quarto, `{rtweet}` updated its default output format. Now, parsing dates and times is not necessary anymore.\nI leave this section in here because the code may still be helpful in other situations.\n\nFirst, I needed to convert the `created_at` column from `character` to `datetime` format.\nThe easiest way to do that gets rid of `+0000` in the character vector and then\nparses the vector into the right format via `parse_date_time()`.\nBut there is a catch. \nCheck out what happens if I try this on my computer.\n\n\n\n::: {.cell mesage='false'}\n\n```{.r .cell-code}\nlibrary(lubridate)\ntl_slice %>% \n  mutate(created_at = parse_date_time(\n    str_remove(created_at, '\\\\+0000'), # remove the +0000 \n    orders = 'a b d H:M:S Y'\n  ))\n```\n:::\n\n\n\nSee how all values in `created_at` are `NA` now?\nThat's a problem.\nAnd we will solve it very soon.\nBut first, let me explain how the function call works.\n\nThe `orders` argument specifies how the vector `created_at` (without `+0000`) is to be understood.\nWe clarify that `created_at` contains (in the order of appearance)\n\n1. abbreviated week day names (`a`)\n2. abbreviated month names (`b`)\n3. the day of the month as decimals (`d`)\n4. and so on\n\nWhere do these abbreviations `a`, `b`, `d`, etc. come from?\nThey are defined in the help page of `parse_date_time()`.\nYou can find them in the section \"Details\".\nBut why does the code not work? \nWhy do we always get an `NA`?\nFor once, my computer is truly the problem.\nOr rather, its settings.\n\nBy default, my computer is set to German.\nBut even if RStudio or R's error messages are set to English, my computer's so-called\n\"locale\" may be still be set to German.\nThat's a problem because abbreviations like \"Sat\" and \"Wed\" refer to \nthe **English** words \"Saturday\" and \"Wednesday\".\nSo, we need to make sure that `parse_date_time()` understands that it needs to use\nan English locale.\nThen, everything works out.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparsed_highlights <- tl_slice %>% \n  mutate(created_at = parse_date_time(\n    str_remove(created_at, '\\\\+0000'), # remove the +0000 \n    orders = 'a b d H:M:S Y',\n    locale = \"en_US.UTF-8\"\n  ))\nparsed_highlights\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nWe are now ready to send this data to ggplot.\nSince `created_at` is formatted in datetime now, ggplot will understand what it\nmeans when we map `x = created_at`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparsed_highlights %>% \n  ggplot(aes(created_at, favorite_count)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](11_track_twitter_followers_files/figure-pdf/unnamed-chunk-12-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n### Using scale_x_date(time) and locale\n\nDid you see that the x-axis uses German abbreviations and doesn't show what year we're in?\nThat's not great.\nLet's change that.\nAs is always the case when we want to format the axes we will need a `scale_*()` function.\nHere, what we need is `scale_x_datetime()`.\n\nBut this won't solve our German locale problem.\nThe easiest way to solve that tricky ordeal is to change the locale globally via `Sys.setlocale()`.\nDon't worry, though.\nThe locale will reset after restarting R.\nNo permanent \"damage\" here.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setlocale(\"LC_ALL\",\"en_US.UTF-8\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=de_DE.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=de_DE.UTF-8;LC_IDENTIFICATION=C\"\n```\n:::\n\n```{.r .cell-code}\np <- parsed_highlights %>% \n  ggplot(aes(created_at, favorite_count)) +\n  geom_line() +\n  scale_x_datetime(\n    date_breaks = '2 months', # break every two months\n    date_labels = '%b %Y'\n  )\np\n```\n\n::: {.cell-output-display}\n![](11_track_twitter_followers_files/figure-pdf/unnamed-chunk-13-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nNotice that we have once again used the same abbreviation as for `parse_date_time()`.\nThis time, though, they have to be preceded by `%`.\nDon't ask me why.\nIt is just the way it is.\n\n### Create new dates\n\nLet us add a rectangle to our previous plot via an annotation.\nThis is similar to what I needed to do when adding my \"mysterious wonderland\" to my plot.\n\nSince the `x` aesthetic is formatted to datetime, we have to specify dates\nfor the `xmin` and `xmax` aesthetic of our annotation.\nTherefore, we need to create dates manually.\nIn this case, `make_datetime()` is the way to go.\nIf we're dealing only with dates (without times), then `make_date()` is a useful pendant.\nBoth functions are quite straightforward.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <- p +\n  annotate(\n    'rect',\n    xmin = make_datetime(year = 2021, month = 11, day = 6, hour = 12),\n    xmax = make_datetime(year = 2021, month = 9), \n    ymin = 200,\n    ymax = 273,\n    alpha = 0.5\n  )\np\n```\n\n::: {.cell-output-display}\n![](11_track_twitter_followers_files/figure-pdf/unnamed-chunk-14-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n### Filter with intervals\n\nMaybe we want to highlight a part of our line.\nTo do so, we could filter our data to check whether certain date ranges correspond\nto parts that we want to highlight.\nUsually when we want to check if a value `x` is within a certain set of `objects` we use\n`x %in% objects`.\n\nTo do the same with dates, we need to create an interval with `interval()` first.\nThen, we can use that in `filter()` in conjunction with `%within%` instead of `%in%`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_interval <- interval(\n  start = make_date(year = 2022, month = 2), \n  end = make_date(year = 2022, month = 3, day = 10)\n)\n\np +\n  geom_line(\n    data = parsed_highlights %>% filter(created_at %within% my_interval),\n    color = 'red',\n    size = 2\n  )\n```\n\n::: {.cell-output-display}\n![](11_track_twitter_followers_files/figure-pdf/unnamed-chunk-15-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n### Calculations with times\n\nSay that you want to highlight the first five days after a certain date.\n(That's exactly what I did in my plot.)\nThen, you can simply add `days(5)` to this date.\nThere are similar functions like `minutes()`, `hours()` and so on.\nLet me show you how that may look in a visualization.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np +\n  annotate(\n    'rect',\n    xmin = parsed_highlights[[1, 'created_at']] - hours(24),\n    xmax = parsed_highlights[[1, 'created_at']] + days(5),\n    ymin = -Inf,\n    ymax = Inf,\n    alpha = 0.25,\n    fill = 'blue'\n  )\n```\n\n::: {.cell-output-display}\n![](11_track_twitter_followers_files/figure-pdf/unnamed-chunk-16-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Closing\n\nThis was a short intro to `lubridate` and `rtweet`.\nNaturally, the evolution of my follower count contained a lot more steps.\nIn the end, though, these steps were merely a collection of\n\n* techniques you know from my two previous storytelling with ggplot posts (see [here](https://albert-rapp.de/posts/ggplot2-tips/10_recreating_swd_look/10_recreating_swd_look.html) and\n[here](https://albert-rapp.de/posts/ggplot2-tips/11_rounded_rectangles/11_rounded_rectangles.html)) plus\n* data wrangling using times and dates with the functions that I just showed you.\n\nOnce again, thank you all for your support.\nAnd if you liked this post and don't follow my work yet, then consider following me on [Twitter](https://twitter.com/rappa753) and/or subscribing to my [RSS feed](https://albert-rapp.de/blog.xml). \nSee you next time!",
    "supporting": [
      "11_track_twitter_followers_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}