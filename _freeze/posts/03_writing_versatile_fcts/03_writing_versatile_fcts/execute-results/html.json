{
  "hash": "2820e4cf355ef35aee3f7838fdffd367",
  "result": {
    "markdown": "---\ntitle: 'Writing Versatile Functions with R'\ndate: '2021-09-16'\ncategories: []\ndescription: \"Using concepts like dot-dot-dot and curly-curly we create functions that are more versatile and can be used in multiple settings.\"\nexecute: \n  message: false\n  warning: false\n  collapse: false\neditor_options: \n  chunk_output_type: console\n---\n\nThis week, I had to deal with two very similar tasks on two very similar but not identical data sets that required me to write a function that is versatile enough to deal with both data sets despite their subtle differences.\nThe differences that had to be accounted for mainly related to using functions in the two cases that relied on differently many arguments.\nAlso, some of the column names were different which meant that I could not hard-code the column names into the function I was creating.\n\nConsequently, I had to use a few non-standard concepts (at least not standard to me) that enabled me to create the function which did everything I asked it to do.\nSince these concepts seemed interesting to me, I decided to implement a small example resulting in this blog post.\nActually, I was even motivated to create a video for this blog post.\nYou can find it [on YouTube](https://youtu.be/L_sX-sL9aWM).\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n## What We Want To Achieve\n\nThe aim of this example is to write a function that can create two tibbles that are conceptually similar but do not necessarily use the same column names or compute the existing columns in the same way.\nFor this blog post, I have already set up two dummy data sets like that so that we can see what we want to do.  \nLet's take a look at these data sets I creatively called `dat_A` and `dat_B`.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndat_A %>% head(3)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 3 × 3\n     mu sigma dat             \n  <dbl> <dbl> <list>          \n1    -1   1   <tibble [5 × 2]>\n2    -1   1.5 <tibble [5 × 2]>\n3    -1   2   <tibble [5 × 2]>\n```\n:::\n\n```{.r .cell-code}\ndat_B %>% head(3)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 3 × 2\n  lambda dat             \n   <dbl> <list>          \n1    0.5 <tibble [5 × 2]>\n2    0.7 <tibble [5 × 2]>\n3    0.9 <tibble [5 × 2]>\n```\n:::\n:::\n\n\nAs you can see, each tibble contains a column `dat`.\nThis column consists of tibbles with multiple summarized stochastic processes which were simulated using parameters that are given by the remaining columns of `dat_A` and `dat_B`.\n\nYou probably have already noticed that the stochastic processes must have been simulated using differently many parameters since tibble A contains additional columns `mu` and `sigma` whereas tibble B can offer only one additional column `lambda`.\nHowever, even if differently many and differently named parameters are used, the logic of the generating function needs to be the same:\n\n1. Take parameters.\n2. Simulate stochastic processes with these parameters.\n3. Summarize processes\n\nThus, in step 1 the generating function which we want to code, needs to be versatile enough to handle different argument names and amounts.\nNext, let's see what the `dat` column has in store for us.\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_A %>% pluck(\"dat\", 1) %>% head(3)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 3 × 2\n      n proc_mean\n  <int>     <dbl>\n1     1    -1.01 \n2     2    -0.958\n3     3    -0.968\n```\n:::\n\n```{.r .cell-code}\ndat_B %>% pluck(\"dat\", 1) %>% head(3)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 3 × 2\n      n proc_variance\n  <int>         <dbl>\n1     1          5.27\n2     2          2.66\n3     3          3.08\n```\n:::\n:::\n\nFirst of all, notice that I accessed the first tibble in the `dat` column using the super neat `pluck()` function.\nIn my opinion, this function is preferable to the clunky base R usage of `$` and `[[`, e.g. like `dat_A$dat[[1]]`.\n\nAs you can see, the tibbles that are saved in `dat` contain columns `n` and `proc_mean` resp. `proc_variance`.\nAs hinted at before, each row is supposed to represent a summary of the `n`-th realization of a stochastic process.\n\nHowever, notice that the summary statistics in use are not the same!\nThe different column names `proc_mean` and `proc_variance` indicate that in tibble A the sample mean was used whereas tibble B contains sample variances.\nAgain, our function that generates `tib_A` and `tib_B` should be flexible enough to create differently named and differently computed columns.\n\n## Helpful Concepts\n\nNow that we know what we want to create, let us begin by learning how to handle differently many arguments and their varying names.\n\n### dot-dot-dot\n\nFor these kinds of purposes, R offers the `...`-operator (pronounced dot-dot-dot).\nBasically, it serves as a placeholder for everything you do not want to evaluate immediately.\n\nFor instance, have you ever wondered how `dplyr`'s `select()` function is able to select the correct column?[^yards-reused]\nIf you're thinking \"No, but what's so special about this?\", then you may want to notice that it is actually not that simple to define your own `select()` function even with the help of the `dplyr` function.\n\nThis is because defining an appropriate function to select two columns from, say, the `iris` data set cannot be done like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_select <- function(x, y) {select(iris, x, y)}\n```\n:::\n\nNow, if you want to use the function the same way you would use `dplyr::select()`, i.e. simply passing, say, `Sepal.Width, Sepal.Length` (notice no `\"\"`) to your new function, it would look like this\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_select(Sepal.Width, Sepal.Length)\n#> Error: object 'Sepal.Width' not found\n```\n:::\n\nThis error appears because at some point, R will try to evaluate the arguments as variables from your current environment.\nBut of course this variable is not present in your environment and only present within the `iris` data set.\nTherefore, what `dplyr::select()` accomplishes is that it lets R know to evaluate the input argument only later on, i.e. when the variable from the data set is \"available\".\n\nThis is where `...` comes into play. \nIt is not by chance that `select()` only has arguments `.data` and `...`. \nHere, `select()` uses that everything which is thrown into `...`, will be passed along to be evaluated later.\nThis can save our `my_select()` function, too.\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_select <- function(...) {select(iris, ...)}\nmy_select(Sepal.Width, Sepal.Length) %>% head(3)\n```\n\n::: {.cell-output-stdout}\n```\n  Sepal.Width Sepal.Length\n1         3.5          5.1\n2         3.0          4.9\n3         3.2          4.7\n```\n:::\n:::\n\n\nWorks like a charm!\nThis will help us to define a function that is flexible enough for our purposes.\nBefore we start with that, let us learn about another ingredient we will use.\n\n### curly-curly\n\nIf we were to only select a single column from `iris` using our `my_select()` function, we could have also written the function using `{{ }}` (pronounced curly-curly).\nIt operators similar to `...` in the sense that it allows for later evaluation but applies this concept to specific variable.\nCheck out how that can be used here.\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_select <- function(x) {select(iris, {{x}})}\nmy_select(Sepal.Width) %>% head(3)\n```\n\n::: {.cell-output-stdout}\n```\n  Sepal.Width\n1         3.5\n2         3.0\n3         3.2\n```\n:::\n:::\n\n\nWhat's more the curly-curly variables - curly-curlied variables (?) - can also be used later on for stuff like naming a new column.\nFor example, let us modify our previous function to demonstrate how that can be used.\n\n::: {.cell}\n\n```{.r .cell-code}\nselect_and_add <- function(x, y) {\n  select(iris, {{x}}) %>% \n    mutate({{y}} := 5) \n  # 5 can be replaced by some meaningful calculation\n}\nselect_and_add(\"Sepal.Width\", \"variable_y\") %>% head(3)\n```\n\n::: {.cell-output-stdout}\n```\n  Sepal.Width variable_y\n1         3.5          5\n2         3.0          5\n3         3.2          5\n```\n:::\n:::\n\nMind the colon!\nHere, if you want to use `y` as column name later on you cannot use the standard `mutate()` syntax but have to use `:=` instead.\n\n### Functional Programming\n\nOne last thing that we will use, is the fact that R supports functional programming.\nThus, we can use functions as arguments of other functions.\nFor instance, take a look at this super simple, yet somewhat useless wrapper function for illustration purposes.\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_simulate <- function(n, func) {\n  func(n)\n}\nset.seed(564)\nmy_simulate(5, rnorm)\n```\n\n::: {.cell-output-stdout}\n```\n[1]  0.4605501 -0.7750968 -0.7159321  0.6882645 -2.0544591\n```\n:::\n:::\n\nAs you just witnessed, I simply passed `rnorm` (without a call using `()`) to `my_simulate` as the `func` argument such that `rnorm` is used whenever `func` is called.\nIn our use case, this functionality can be used to simulate different stochastic processes (that may depend on different parameters).\n\n## The Implementation\n\nAlright, we have assembled everything we need in order to create our `simulate_and_summarize_proc()` function.\nIn this example, the simulation of the stochastic processes will consist of simply calling `rnorm()` or `rexp()` but, of course, these functions can be substituted with arbitrarily complex simulation functions.\n\nWe will use `n_simus` as the amount of realizations that are supposed to be simulated and each realization will be of length `TMax`.\nFurther, we will use `...` to handle an arbitrary amount of parameters that are supposed to be passed to `simulation_func`.\nSo, let's implement the simulation part first (detailed explanations below).\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_and_summarize_proc <- \n  function(..., TMax, n_simus, simulation_func) {\n    argslist <- list(n = TMax, ...) %>% \n      map(~rep(., n_simus))\n    \n    tibble(\n      t = list(1:TMax),\n      n = 1:n_simus,\n      value = pmap(argslist, simulation_func)\n    ) \n  }\nset.seed(457)\nsimulate_and_summarize_proc(\n  mean = 1,\n  sd = 2,\n  TMax = 200, \n  n_simus = 3, \n  simulation_func = rnorm # arguments -> n, mean, sd\n) \n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 3 × 3\n  t               n value      \n  <list>      <int> <list>     \n1 <int [200]>     1 <dbl [200]>\n2 <int [200]>     2 <dbl [200]>\n3 <int [200]>     3 <dbl [200]>\n```\n:::\n:::\n\n\nAs you can see, this created three (simple) stochastic processes of length 200 using the parameters `mean = 1` and `sd = 2`.\nWe can validate that the correct parameters were used once we implement the summary functions.\n\nFirst, let us address the tricky part in this function.\nIn order to pass a list of arguments to `pmap()` that are then used with `simulation_func`, we first need to rearrange the lists a bit.\nAfter the first step, by simply putting everything from `...` into the list we have a list like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(n = 100, mean = 1, sd = 2) %>% str()\n```\n\n::: {.cell-output-stdout}\n```\nList of 3\n $ n   : num 100\n $ mean: num 1\n $ sd  : num 2\n```\n:::\n:::\n\nHowever, we will need to have each variable in the list repeated `n_simus` time in order to simulate more than one realization.\nThus, we use `map()` to replicate:\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(n = 200, mean = 1, sd = 2) %>% \n  map(~rep(., 3)) %>% \n  str()\n```\n\n::: {.cell-output-stdout}\n```\nList of 3\n $ n   : num [1:3] 200 200 200\n $ mean: num [1:3] 1 1 1\n $ sd  : num [1:3] 2 2 2\n```\n:::\n:::\n\nNote that calling `rep()` without `map()` does not cause an error but does not  deliver the appropriate format:\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(n = 100, mean = 1, sd = 2) %>% \n  rep(3) %>% \n  str()\n```\n\n::: {.cell-output-stdout}\n```\nList of 9\n $ n   : num 100\n $ mean: num 1\n $ sd  : num 2\n $ n   : num 100\n $ mean: num 1\n $ sd  : num 2\n $ n   : num 100\n $ mean: num 1\n $ sd  : num 2\n```\n:::\n:::\n\nNext, let us take the current output and implement the summary.\nTo do so, we will add another variables `summary_name` and `summary_func` to the function in order to choose a column name resp. a summary statistic. \n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_and_summarize_proc <- \n  function(..., TMax, n_simus, simulation_func, summary_name, summary_func) {\n    argslist <- list(n = TMax, ...) %>% \n      map(~rep(., n_simus))\n    \n    tibble(\n      t = list(1:TMax),\n      n = 1:n_simus,\n      value = pmap(argslist, simulation_func)\n    ) %>% # this part is added\n      unnest(c(t, value)) %>% \n      group_by(n) %>%\n      summarise({{summary_name}} := summary_func(value))\n  }\nset.seed(457)\nsimulate_and_summarize_proc(\n  mean = 1,\n  sd = 2,\n  TMax = 200, \n  n_simus = 5, \n  simulation_func = rnorm, \n  summary_name = \"mega_awesome_mean\", \n  summary_func = mean\n) \n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 5 × 2\n      n mega_awesome_mean\n  <int>             <dbl>\n1     1             0.955\n2     2             0.932\n3     3             0.987\n4     4             1.07 \n5     5             1.15 \n```\n:::\n:::\n\nFinally, we can use our super versatile function in combination with `map()` to create `dat_A` and `dat_B`.\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_A <- \n  expand_grid(\n    mu = seq(-1, 1, 0.25),\n    sigma = seq(1, 3, 0.5)\n  ) %>% \n  mutate(dat = map2(\n    mu, sigma, \n    ~simulate_and_summarize_proc(\n      mean = .x, \n      sd = .y, \n      TMax = 200, \n      n_simus = 3, \n      simulation_func = rnorm, \n      summary_name = \"proc_mean\", \n      summary_func = mean\n    )\n  ))\n  \n\ndat_B <- \n  expand_grid(\n    lambda = seq(0.5, 1.5, 0.2)\n  ) %>% \n  mutate(dat = map(\n    lambda, \n    ~simulate_and_summarize_proc(\n      rate = .,\n      TMax = 200, \n      n_simus = 3, \n      simulation_func = rexp, \n      summary_name = \"proc_variance\", \n      summary_func = var\n    )\n  ))\n```\n:::\n\n## Conclusion\n\nSo, we have seen that we can combine `{{ }}`,  `...` and functional programming to create highly versatile functions.\nOf course, as always one might be tempted to say that one could have just programmed two different functions for our particular example.\n\nHowever, this would cause a lot of code duplication because a lot of steps are essentially the same which is hard to debug and maintain.\nAlso, creating numerous functions does not scale well if we need to cover way more than two cases.\n\nWith that being said, I hope that you found this blog post helpful and if so, feel free to hit the comments or push the applause button below.\nSee you next time.\n\n[^yards-reused]: If you have read my [YARDS lecture notes](https://yards.albert-rapp.de/index.html) and this sounds familiar to you, you are absolutely right.\nI have reused and adapted a part of the \"Choose Your Own Data Science Adventure\"-chapter here.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}